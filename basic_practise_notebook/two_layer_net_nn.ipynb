{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: nn\n",
    "-----------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer, trained to predict y from x\n",
    "by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation uses the nn package from PyTorch to build the network.\n",
    "PyTorch autograd makes it easy to define computational graphs and take gradients,\n",
    "but raw autograd can be a bit too low-level for defining complex neural networks;\n",
    "this is where the nn package can help. The nn package defines a set of Modules,\n",
    "which you can think of as a neural network layer that has produces output from\n",
    "input and may have some trainable weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 672.3374633789062\n",
      "1 622.8316040039062\n",
      "2 579.5445556640625\n",
      "3 541.4376831054688\n",
      "4 507.4725646972656\n",
      "5 477.0326232910156\n",
      "6 449.6767883300781\n",
      "7 424.53094482421875\n",
      "8 401.20355224609375\n",
      "9 379.6190490722656\n",
      "10 359.6780700683594\n",
      "11 340.9647521972656\n",
      "12 323.36737060546875\n",
      "13 306.7540283203125\n",
      "14 290.9610900878906\n",
      "15 275.8394775390625\n",
      "16 261.40625\n",
      "17 247.704345703125\n",
      "18 234.6118621826172\n",
      "19 222.13772583007812\n",
      "20 210.2431640625\n",
      "21 198.9040985107422\n",
      "22 188.09007263183594\n",
      "23 177.8012237548828\n",
      "24 167.99868774414062\n",
      "25 158.65406799316406\n",
      "26 149.75830078125\n",
      "27 141.28176879882812\n",
      "28 133.23516845703125\n",
      "29 125.59796142578125\n",
      "30 118.3651351928711\n",
      "31 111.5326156616211\n",
      "32 105.07860565185547\n",
      "33 99.00236511230469\n",
      "34 93.26808166503906\n",
      "35 87.85501861572266\n",
      "36 82.76030731201172\n",
      "37 77.95792388916016\n",
      "38 73.43431854248047\n",
      "39 69.17705535888672\n",
      "40 65.17559051513672\n",
      "41 61.42422103881836\n",
      "42 57.9016227722168\n",
      "43 54.58761978149414\n",
      "44 51.47725296020508\n",
      "45 48.551536560058594\n",
      "46 45.80130386352539\n",
      "47 43.2195930480957\n",
      "48 40.7953987121582\n",
      "49 38.516868591308594\n",
      "50 36.38163375854492\n",
      "51 34.3759765625\n",
      "52 32.492183685302734\n",
      "53 30.72199058532715\n",
      "54 29.057151794433594\n",
      "55 27.48940658569336\n",
      "56 26.005517959594727\n",
      "57 24.60890007019043\n",
      "58 23.294227600097656\n",
      "59 22.0566349029541\n",
      "60 20.890438079833984\n",
      "61 19.7941837310791\n",
      "62 18.761539459228516\n",
      "63 17.787254333496094\n",
      "64 16.870101928710938\n",
      "65 16.005020141601562\n",
      "66 15.189471244812012\n",
      "67 14.419261932373047\n",
      "68 13.688384056091309\n",
      "69 12.99838638305664\n",
      "70 12.34650707244873\n",
      "71 11.730476379394531\n",
      "72 11.148884773254395\n",
      "73 10.597784042358398\n",
      "74 10.076663970947266\n",
      "75 9.583510398864746\n",
      "76 9.11660099029541\n",
      "77 8.674615859985352\n",
      "78 8.255966186523438\n",
      "79 7.859219074249268\n",
      "80 7.48276948928833\n",
      "81 7.125761985778809\n",
      "82 6.787960529327393\n",
      "83 6.4651780128479\n",
      "84 6.159246921539307\n",
      "85 5.868540287017822\n",
      "86 5.592747688293457\n",
      "87 5.331363201141357\n",
      "88 5.0832600593566895\n",
      "89 4.847558975219727\n",
      "90 4.624075889587402\n",
      "91 4.4117207527160645\n",
      "92 4.210115432739258\n",
      "93 4.01819372177124\n",
      "94 3.835732936859131\n",
      "95 3.6624112129211426\n",
      "96 3.4976844787597656\n",
      "97 3.340911626815796\n",
      "98 3.191509485244751\n",
      "99 3.0493054389953613\n",
      "100 2.9141643047332764\n",
      "101 2.785510301589966\n",
      "102 2.663299560546875\n",
      "103 2.5469894409179688\n",
      "104 2.436228036880493\n",
      "105 2.330620288848877\n",
      "106 2.2300047874450684\n",
      "107 2.134106159210205\n",
      "108 2.042616128921509\n",
      "109 1.9553580284118652\n",
      "110 1.8721059560775757\n",
      "111 1.792803406715393\n",
      "112 1.7171217203140259\n",
      "113 1.644853115081787\n",
      "114 1.5757794380187988\n",
      "115 1.5099116563796997\n",
      "116 1.446985125541687\n",
      "117 1.3869409561157227\n",
      "118 1.3296459913253784\n",
      "119 1.274940848350525\n",
      "120 1.222615361213684\n",
      "121 1.1726560592651367\n",
      "122 1.124877691268921\n",
      "123 1.0791877508163452\n",
      "124 1.0354454517364502\n",
      "125 0.9936599731445312\n",
      "126 0.9536834955215454\n",
      "127 0.915416955947876\n",
      "128 0.8788439035415649\n",
      "129 0.8438562154769897\n",
      "130 0.8103735446929932\n",
      "131 0.7783800959587097\n",
      "132 0.7477061748504639\n",
      "133 0.7183142304420471\n",
      "134 0.6901726722717285\n",
      "135 0.6632298827171326\n",
      "136 0.637418270111084\n",
      "137 0.612694501876831\n",
      "138 0.5889253616333008\n",
      "139 0.5661547183990479\n",
      "140 0.5443295240402222\n",
      "141 0.5234063267707825\n",
      "142 0.5033708810806274\n",
      "143 0.4842599332332611\n",
      "144 0.4659773111343384\n",
      "145 0.448439359664917\n",
      "146 0.4316144287586212\n",
      "147 0.4154875874519348\n",
      "148 0.4000343084335327\n",
      "149 0.3851984739303589\n",
      "150 0.3709567189216614\n",
      "151 0.3572880029678345\n",
      "152 0.3441616892814636\n",
      "153 0.33156025409698486\n",
      "154 0.31946876645088196\n",
      "155 0.3078557550907135\n",
      "156 0.2966947555541992\n",
      "157 0.28596436977386475\n",
      "158 0.2756560444831848\n",
      "159 0.2657500207424164\n",
      "160 0.2562240958213806\n",
      "161 0.24706168472766876\n",
      "162 0.23826122283935547\n",
      "163 0.2297973334789276\n",
      "164 0.22166648507118225\n",
      "165 0.21383769810199738\n",
      "166 0.20630799233913422\n",
      "167 0.19906242191791534\n",
      "168 0.19208797812461853\n",
      "169 0.1853816956281662\n",
      "170 0.1789272576570511\n",
      "171 0.172714963555336\n",
      "172 0.16673524677753448\n",
      "173 0.1609848439693451\n",
      "174 0.15544627606868744\n",
      "175 0.15010903775691986\n",
      "176 0.144967183470726\n",
      "177 0.1400180608034134\n",
      "178 0.13525423407554626\n",
      "179 0.13066363334655762\n",
      "180 0.1262378692626953\n",
      "181 0.12197136133909225\n",
      "182 0.11785966902971268\n",
      "183 0.11390732228755951\n",
      "184 0.11008886992931366\n",
      "185 0.10640554130077362\n",
      "186 0.10285703092813492\n",
      "187 0.09944280982017517\n",
      "188 0.09615369141101837\n",
      "189 0.09297847747802734\n",
      "190 0.08991334587335587\n",
      "191 0.08695818483829498\n",
      "192 0.0841100811958313\n",
      "193 0.08135893195867538\n",
      "194 0.0787011906504631\n",
      "195 0.07613882422447205\n",
      "196 0.07366672158241272\n",
      "197 0.07127851247787476\n",
      "198 0.06897357851266861\n",
      "199 0.06674850732088089\n",
      "200 0.0645994320511818\n",
      "201 0.06252558529376984\n",
      "202 0.060523148626089096\n",
      "203 0.05858806148171425\n",
      "204 0.05671929568052292\n",
      "205 0.05491397902369499\n",
      "206 0.05316891148686409\n",
      "207 0.05148407071828842\n",
      "208 0.049855608493089676\n",
      "209 0.04828125238418579\n",
      "210 0.046762023121118546\n",
      "211 0.04529277980327606\n",
      "212 0.0438716895878315\n",
      "213 0.04249853268265724\n",
      "214 0.041171275079250336\n",
      "215 0.03989000990986824\n",
      "216 0.038648784160614014\n",
      "217 0.03744865953922272\n",
      "218 0.03628907725214958\n",
      "219 0.035166651010513306\n",
      "220 0.03408060595393181\n",
      "221 0.033030420541763306\n",
      "222 0.03201505169272423\n",
      "223 0.031032370403409004\n",
      "224 0.030082514509558678\n",
      "225 0.02916269563138485\n",
      "226 0.02827260084450245\n",
      "227 0.0274114441126585\n",
      "228 0.026577666401863098\n",
      "229 0.025771217420697212\n",
      "230 0.02499094419181347\n",
      "231 0.024236025288701057\n",
      "232 0.023505140095949173\n",
      "233 0.02279728092253208\n",
      "234 0.022112064063549042\n",
      "235 0.02144904062151909\n",
      "236 0.02080634795129299\n",
      "237 0.02018437348306179\n",
      "238 0.01958181895315647\n",
      "239 0.01899927295744419\n",
      "240 0.018434006720781326\n",
      "241 0.017886605113744736\n",
      "242 0.01735624112188816\n",
      "243 0.01684250682592392\n",
      "244 0.01634439080953598\n",
      "245 0.01586202159523964\n",
      "246 0.015394547954201698\n",
      "247 0.014941588044166565\n",
      "248 0.014502511359751225\n",
      "249 0.014076999388635159\n",
      "250 0.01366480439901352\n",
      "251 0.013265389017760754\n",
      "252 0.012878534384071827\n",
      "253 0.012502910569310188\n",
      "254 0.012138841673731804\n",
      "255 0.011785777285695076\n",
      "256 0.011443610303103924\n",
      "257 0.011111875995993614\n",
      "258 0.010790251195430756\n",
      "259 0.010478092357516289\n",
      "260 0.010175535455346107\n",
      "261 0.009882067330181599\n",
      "262 0.009597430005669594\n",
      "263 0.009321392513811588\n",
      "264 0.009053649380803108\n",
      "265 0.008793998509645462\n",
      "266 0.008542140014469624\n",
      "267 0.00829783733934164\n",
      "268 0.008060766384005547\n",
      "269 0.007830662652850151\n",
      "270 0.0076075210236012936\n",
      "271 0.007391012739390135\n",
      "272 0.007180905435234308\n",
      "273 0.006976975593715906\n",
      "274 0.006779100280255079\n",
      "275 0.006587020121514797\n",
      "276 0.006400558166205883\n",
      "277 0.006219695787876844\n",
      "278 0.006044108420610428\n",
      "279 0.005873757880181074\n",
      "280 0.005708450451493263\n",
      "281 0.005547849927097559\n",
      "282 0.005391943734139204\n",
      "283 0.00524053955450654\n",
      "284 0.00509359547868371\n",
      "285 0.004950941074639559\n",
      "286 0.004812578205019236\n",
      "287 0.004678305704146624\n",
      "288 0.004547686781734228\n",
      "289 0.004420834127813578\n",
      "290 0.004297677427530289\n",
      "291 0.004178098402917385\n",
      "292 0.004061938729137182\n",
      "293 0.003949177451431751\n",
      "294 0.0038396476302295923\n",
      "295 0.0037332414649426937\n",
      "296 0.003629897488281131\n",
      "297 0.003529592417180538\n",
      "298 0.0034322147257626057\n",
      "299 0.0033374433405697346\n",
      "300 0.0032453963067382574\n",
      "301 0.003155957907438278\n",
      "302 0.003069066209718585\n",
      "303 0.002984686056151986\n",
      "304 0.0029027126729488373\n",
      "305 0.0028230161406099796\n",
      "306 0.002745592501014471\n",
      "307 0.0026703993789851665\n",
      "308 0.0025972884614020586\n",
      "309 0.002526242285966873\n",
      "310 0.00245721940882504\n",
      "311 0.002390131587162614\n",
      "312 0.0023249476216733456\n",
      "313 0.002261592075228691\n",
      "314 0.0022000111639499664\n",
      "315 0.0021401422563940287\n",
      "316 0.0020819678902626038\n",
      "317 0.0020254713017493486\n",
      "318 0.0019704862497746944\n",
      "319 0.0019170637242496014\n",
      "320 0.001865137368440628\n",
      "321 0.0018146345391869545\n",
      "322 0.0017655445262789726\n",
      "323 0.0017178072594106197\n",
      "324 0.0016713986406102777\n",
      "325 0.0016262804856523871\n",
      "326 0.0015824399888515472\n",
      "327 0.0015398068353533745\n",
      "328 0.0014983674045652151\n",
      "329 0.0014580611605197191\n",
      "330 0.0014188664499670267\n",
      "331 0.001380722620524466\n",
      "332 0.0013436772860586643\n",
      "333 0.0013076395262032747\n",
      "334 0.0012725753476843238\n",
      "335 0.001238486380316317\n",
      "336 0.0012053390964865685\n",
      "337 0.001173109165392816\n",
      "338 0.001141820102930069\n",
      "339 0.0011113365180790424\n",
      "340 0.0010816812282428145\n",
      "341 0.001052818726748228\n",
      "342 0.0010247553000226617\n",
      "343 0.00099745683837682\n",
      "344 0.0009709130972623825\n",
      "345 0.0009450938086956739\n",
      "346 0.0009199634077958763\n",
      "347 0.0008955230587162077\n",
      "348 0.0008717340533621609\n",
      "349 0.0008486052975058556\n",
      "350 0.0008261046605184674\n",
      "351 0.0008042193949222565\n",
      "352 0.0007829259848222136\n",
      "353 0.0007622080738656223\n",
      "354 0.0007420377223752439\n",
      "355 0.0007224548025988042\n",
      "356 0.0007033817819319665\n",
      "357 0.0006848123739473522\n",
      "358 0.0006667336565442383\n",
      "359 0.0006491518579423428\n",
      "360 0.000632039736956358\n",
      "361 0.0006153768626973033\n",
      "362 0.0005991901271045208\n",
      "363 0.0005834176554344594\n",
      "364 0.0005680937319993973\n",
      "365 0.0005531655624508858\n",
      "366 0.0005386343691498041\n",
      "367 0.0005244876374490559\n",
      "368 0.0005107337492518127\n",
      "369 0.0004973406903445721\n",
      "370 0.00048430205788463354\n",
      "371 0.00047161089605651796\n",
      "372 0.00045925736776553094\n",
      "373 0.0004472441505640745\n",
      "374 0.00043554697185754776\n",
      "375 0.00042416350333951414\n",
      "376 0.00041307322680950165\n",
      "377 0.00040229206206277013\n",
      "378 0.0003917852009180933\n",
      "379 0.0003815616655629128\n",
      "380 0.0003716197388712317\n",
      "381 0.0003619339258875698\n",
      "382 0.00035250172368250787\n",
      "383 0.0003433210076764226\n",
      "384 0.0003344078140798956\n",
      "385 0.0003257138596381992\n",
      "386 0.0003172424912918359\n",
      "387 0.00030899778357706964\n",
      "388 0.00030096733826212585\n",
      "389 0.0002931527851615101\n",
      "390 0.0002855489437934011\n",
      "391 0.00027813651831820607\n",
      "392 0.0002709296823013574\n",
      "393 0.0002639006415847689\n",
      "394 0.00025706019368954003\n",
      "395 0.0002504088042769581\n",
      "396 0.00024392892373725772\n",
      "397 0.00023761768534313887\n",
      "398 0.00023146891908254474\n",
      "399 0.00022548343986272812\n",
      "400 0.00021965397172607481\n",
      "401 0.00021398514218162745\n",
      "402 0.0002084595907945186\n",
      "403 0.0002030761679634452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 0.00019783942843787372\n",
      "405 0.0001927333214553073\n",
      "406 0.00018776686920318753\n",
      "407 0.00018293235916644335\n",
      "408 0.0001782204199116677\n",
      "409 0.0001736285339575261\n",
      "410 0.00016915662854444236\n",
      "411 0.00016480610065627843\n",
      "412 0.00016056756430771202\n",
      "413 0.00015644283848814666\n",
      "414 0.0001524184044683352\n",
      "415 0.0001485020329710096\n",
      "416 0.0001446915848646313\n",
      "417 0.00014097595703788102\n",
      "418 0.00013735622633248568\n",
      "419 0.0001338325091637671\n",
      "420 0.00013040473277214915\n",
      "421 0.0001270573993679136\n",
      "422 0.00012380363477859646\n",
      "423 0.00012063657777616754\n",
      "424 0.00011754750448744744\n",
      "425 0.00011454063496785238\n",
      "426 0.00011161617294419557\n",
      "427 0.00010876158194150776\n",
      "428 0.00010597630171105266\n",
      "429 0.00010327166819479316\n",
      "430 0.00010063287481898442\n",
      "431 9.80604236247018e-05\n",
      "432 9.555993165122345e-05\n",
      "433 9.311562462244183e-05\n",
      "434 9.074102126760408e-05\n",
      "435 8.842781971907243e-05\n",
      "436 8.617312414571643e-05\n",
      "437 8.39749991428107e-05\n",
      "438 8.18328044260852e-05\n",
      "439 7.974783511599526e-05\n",
      "440 7.771500531816855e-05\n",
      "441 7.5736636063084e-05\n",
      "442 7.380811439361423e-05\n",
      "443 7.193123747128993e-05\n",
      "444 7.009850378381088e-05\n",
      "445 6.831537029938772e-05\n",
      "446 6.657900667050853e-05\n",
      "447 6.488927465397865e-05\n",
      "448 6.324098649201915e-05\n",
      "449 6.163369107525796e-05\n",
      "450 6.006540570524521e-05\n",
      "451 5.854077608091757e-05\n",
      "452 5.705624062102288e-05\n",
      "453 5.5609129049116746e-05\n",
      "454 5.419753142632544e-05\n",
      "455 5.2822237194050103e-05\n",
      "456 5.148231139173731e-05\n",
      "457 5.0177266530226916e-05\n",
      "458 4.890394484391436e-05\n",
      "459 4.766541678691283e-05\n",
      "460 4.6459303121082485e-05\n",
      "461 4.52827152912505e-05\n",
      "462 4.413632632349618e-05\n",
      "463 4.302099114283919e-05\n",
      "464 4.1930466977646574e-05\n",
      "465 4.087260094820522e-05\n",
      "466 3.983940405305475e-05\n",
      "467 3.88332009606529e-05\n",
      "468 3.785044827964157e-05\n",
      "469 3.6895566154271364e-05\n",
      "470 3.5963057598564774e-05\n",
      "471 3.5055338230449706e-05\n",
      "472 3.4171378501923755e-05\n",
      "473 3.330823892611079e-05\n",
      "474 3.2467025448568165e-05\n",
      "475 3.164662848575972e-05\n",
      "476 3.0849034374114126e-05\n",
      "477 3.007183659065049e-05\n",
      "478 2.9312817787285894e-05\n",
      "479 2.8574491807376035e-05\n",
      "480 2.7855234293383546e-05\n",
      "481 2.7151776521350257e-05\n",
      "482 2.6469484510016628e-05\n",
      "483 2.5801668016356416e-05\n",
      "484 2.515093729016371e-05\n",
      "485 2.451967156957835e-05\n",
      "486 2.3902935936348513e-05\n",
      "487 2.3300828615901992e-05\n",
      "488 2.2714491933584213e-05\n",
      "489 2.2145217371871695e-05\n",
      "490 2.158668212359771e-05\n",
      "491 2.1044575987616554e-05\n",
      "492 2.0515257347142324e-05\n",
      "493 2.0000021322630346e-05\n",
      "494 1.9497403627610765e-05\n",
      "495 1.900824463518802e-05\n",
      "496 1.853027606557589e-05\n",
      "497 1.8065156837110408e-05\n",
      "498 1.7611650036997162e-05\n",
      "499 1.7169957573059946e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Variable of input data to the Module and it produces\n",
    "    # a Variable of output data.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss. We pass Variables containing the predicted and true\n",
    "    # values of y, and the loss function returns a Variable containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Variables with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Variable, so\n",
    "    # we can access its data and gradients like we did before.\n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
